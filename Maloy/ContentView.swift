import SwiftUI
import AVFoundation
import Combine

struct ContentView: View {
    @StateObject private var audioManager = AudioManager()
    @EnvironmentObject var mediaPlayerManager: MediaPlayerManager

    // Helper —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –∫–Ω–æ–ø–∫–∏
    private func getButtonText() -> String {
        if audioManager.isAutoMode {
            if audioManager.isProcessing {
                return "‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞..."
            } else if audioManager.isListening {
                return "üõë –ü–†–ï–†–í–ê–¢–¨"
            } else {
                return "üëÇ –°–ª—É—à–∞—é..."
            }
        } else {
            if audioManager.isListening {
                return "üõë –°–¢–û–ü"
            } else if audioManager.isProcessing {
                return "‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞..."
            } else {
                return "üéôÔ∏è –ì–û–í–û–†–ò"
            }
        }
    }

    private func getButtonColor() -> Color {
        if audioManager.isAutoMode {
            if audioManager.isProcessing {
                return .gray
            } else if audioManager.isListening {
                return .red
            } else {
                return .green
            }
        } else {
            if audioManager.isListening {
                return .red
            } else if audioManager.isProcessing {
                return .gray
            } else {
                return .blue
            }
        }
    }

    var body: some View {
        VStack(spacing: 30) {
            // Apple Music status indicator (top right corner)
            HStack {
                Spacer()
                if mediaPlayerManager.isAuthorized {
                    Text("‚úÖ Apple Music")
                        .font(.system(size: 14))
                        .foregroundColor(.green)
                        .padding(.horizontal, 15)
                        .padding(.vertical, 8)
                } else {
                    Text("‚ö†Ô∏è –ù—É–∂–µ–Ω Apple Music")
                        .font(.system(size: 14))
                        .foregroundColor(.orange)
                        .padding(.horizontal, 15)
                        .padding(.vertical, 8)
                }
            }
            .padding(.horizontal)

            Text(audioManager.statusText)
                .font(.title).bold()
                .padding()

            if !audioManager.recognizedText.isEmpty {
                Text("üëÇ \(audioManager.recognizedText)")
                    .foregroundColor(.gray)
                    .padding()
                    .multilineTextAlignment(.center)
            }

            if !audioManager.responseText.isEmpty {
                Text("üí¨ \(audioManager.responseText)")
                    .padding()
                    .multilineTextAlignment(.center)
            }

            Spacer()

            // –ö–Ω–æ–ø–∫–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            Button(action: {
                if audioManager.isAutoMode {
                    // –í –∞–≤—Ç–æ —Ä–µ–∂–∏–º–µ: –ü–†–ï–†–í–ê–¢–¨ –≤—Å—ë
                    audioManager.interrupt()
                } else {
                    // –í —Ä—É—á–Ω–æ–º —Ä–µ–∂–∏–º–µ: —Å—Ç–∞—Ä—Ç/—Å—Ç–æ–ø
                    if audioManager.isListening {
                        audioManager.stopListening()
                    } else if !audioManager.isProcessing {
                        audioManager.startListening()
                    }
                }
            }) {
                Text(getButtonText())
                    .font(.system(size: 32, weight: .bold))
                    .foregroundColor(.white)
                    .frame(width: 320, height: 120)
                    .background(getButtonColor())
                    .cornerRadius(20)
            }
            .padding(.bottom, 20)

            // –ú–∞–ª–µ–Ω—å–∫–∏–µ –∫–Ω–æ–ø–∫–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            HStack(spacing: 15) {
                // –ö–Ω–æ–ø–∫–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è —Ä–µ–∂–∏–º–∞
                Button(action: {
                    audioManager.isAutoMode.toggle()
                    if audioManager.isAutoMode {
                        audioManager.startListeningAuto()
                    } else {
                        audioManager.interrupt()
                    }
                }) {
                    Text(audioManager.isAutoMode ? "ü§ñ –ê–≤—Ç–æ" : "‚úã –†—É—á–Ω–æ–π")
                        .font(.system(size: 16))
                        .foregroundColor(.white)
                        .padding(.horizontal, 20)
                        .padding(.vertical, 10)
                        .background(Color.orange)
                        .cornerRadius(10)
                }

                // –ö–Ω–æ–ø–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏
                Button(action: {
                    audioManager.clearHistory()
                }) {
                    Text("üóëÔ∏è –ù–æ–≤—ã–π —Ä–∞–∑–≥–æ–≤–æ—Ä")
                        .font(.system(size: 16))
                        .foregroundColor(.white)
                        .padding(.horizontal, 20)
                        .padding(.vertical, 10)
                        .background(Color.purple)
                        .cornerRadius(10)
                }
            }
            .padding(.bottom, 30)
        }
        .padding()
        .onAppear {
            audioManager.mediaPlayerManager = mediaPlayerManager
            audioManager.sayGreeting()
        }
    }
}

// MARK: - AUDIO MANAGER

final class AudioManager: NSObject, ObservableObject {
    @Published var recognizedText = ""
    @Published var responseText = ""
    @Published var statusText = "ü§ñ –ú–∞–ª–æ–π"
    @Published var isListening = false
    @Published var isProcessing = false
    @Published var isAutoMode = true  // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

    // API key is stored in Config.swift (not tracked in git for security)
    private let openAIKey = Config.openAIKey

    // MediaPlayer manager (passed from ContentView)
    var mediaPlayerManager: MediaPlayerManager?

    private let audioFilename = FileManager.default.temporaryDirectory.appendingPathComponent("input.wav")
    private var audioEngine: AVAudioEngine?
    private var audioFile: AVAudioFile?
    private var player: AVAudioPlayer?
    private var isSpeaking = false

    // VAD (Voice Activity Detection) –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    private var silenceTimer: Timer?
    private var lastSpeechTime = Date()
    private let silenceThreshold: TimeInterval = 1.5  // 1.5 —Å–µ–∫ —Ç–∏—à–∏–Ω—ã ‚Üí —Å—Ç–æ–ø
    private let speechThreshold: Float = -40.0  // –¥–ë, –≤—ã—à–µ –∫–æ—Ç–æ—Ä–æ–≥–æ —Å—á–∏—Ç–∞–µ–º —Ä–µ—á—å—é

    // –ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ GPT
    private var conversationHistory: [[String: Any]] = []
    private let maxHistoryPairs = 4  // –•—Ä–∞–Ω–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 4 –ø–∞—Ä—ã –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç (8 —Å–æ–æ–±—â–µ–Ω–∏–π)

    // –§–ª–∞–≥ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –º—É–∑—ã–∫–∞–ª—å–Ω—ã—Ö –∫–æ–º–∞–Ω–¥
    private var lastCommandWasMusic = false

    // MARK: –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
    func sayGreeting() {
        // –ó–∞–ø—Ä–µ—â–∞–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É —ç–∫—Ä–∞–Ω–∞ –ø–æ–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ
        UIApplication.shared.isIdleTimerDisabled = true
        print("‚úÖ Screen lock disabled - device will stay awake")

        statusText = "üó£Ô∏è –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ..."
        say("–ü—Ä–∏–≤–µ—Ç, —è –ú–∞–ª–æ–π! –ü—Ä–æ—Å—Ç–æ –≥–æ–≤–æ—Ä–∏, —è —Å–ª—É—à–∞—é.") {
            DispatchQueue.main.async {
                if self.isAutoMode {
                    self.startListeningAuto()
                } else {
                    self.statusText = "üí§ –ñ–¥—É –∫–æ–º–∞–Ω–¥—ã"
                }
            }
        }
    }

    // MARK: –°–ª—É—à–∞–Ω–∏–µ (—Ä—É—á–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º –±—É—Ñ–µ—Ä–æ–º)
    func startListening() {
        guard !isSpeaking && !isProcessing else {
            print("‚ö†Ô∏è Cannot start: isSpeaking=\(isSpeaking), isProcessing=\(isProcessing)")
            return
        }

        print("\n========== –ù–ê–ß–ê–õ–û –ó–ê–ü–ò–°–ò ==========")
        recognizedText = ""
        responseText = ""
        isListening = true
        statusText = "üéôÔ∏è –°–ª—É—à–∞—é..."
        lastCommandWasMusic = false  // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –ø—Ä–∏ –Ω–æ–≤–æ–º –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–∏

        // –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –∑–∞–ø–∏—Å—å - –∏—Å–ø–æ–ª—å–∑—É–µ–º .playAndRecord —á—Ç–æ–±—ã –ù–ï —É–±–∏–≤–∞—Ç—å Spotify
        do {
            try AVAudioSession.sharedInstance().setCategory(.playAndRecord, mode: .default, options: [.allowBluetoothHFP, .duckOthers, .mixWithOthers, .defaultToSpeaker])
            try AVAudioSession.sharedInstance().setActive(true, options: .notifyOthersOnDeactivation)
            print("‚úÖ Audio session configured for recording (Spotify compatible)")
        } catch {
            print("‚ùå Audio session record error:", error)
            stopListening()
            return
        }

        let engine = AVAudioEngine()
        audioEngine = engine
        let input = engine.inputNode

        // –ß–∏—Å—Ç–∏–º –ø—Ä–µ–∂–Ω–∏–π tap
        input.removeTap(onBus: 0)

        // –ü–æ–ª—É—á–∞–µ–º —Ñ–æ—Ä–º–∞—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –ª—é–±–æ–π - –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π, –Ω–∞—É—à–Ω–∏–∫–∏, bluetooth)
        let inputFormat = input.outputFormat(forBus: 0)

        print("üé§ Recording format: \(inputFormat.sampleRate)Hz, \(inputFormat.channelCount) ch, \(inputFormat.commonFormat.rawValue)")

        // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è tap (–±–µ–∑ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏)
        do {
            audioFile = try AVAudioFile(forWriting: audioFilename,
                                        settings: inputFormat.settings,
                                        commonFormat: .pcmFormatFloat32,
                                        interleaved: false)
            print("‚úÖ Audio file created: \(audioFilename.path)")
        } catch {
            print("‚ùå Audio file error:", error)
            stopListening()
            return
        }

        // –£–í–ï–õ–ò–ß–ï–ù–ù–´–ô bufferSize: 4096 ‚Üí 8192 –¥–ª—è –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ–π –∑–∞–ø–∏—Å–∏
        // –≠—Ç–æ –¥–∞–µ—Ç –±–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –∑–∞–ø–∏—Å—å –±—É—Ñ–µ—Ä–∞ –≤ —Ñ–∞–π–ª
        input.installTap(onBus: 0, bufferSize: 8192, format: inputFormat) { [weak self] buffer, time in
            guard let self = self else { return }

            // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –±—É—Ñ–µ—Ä –≤ —Ñ–∞–π–ª —Å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –æ—à–∏–±–æ–∫
            do {
                try self.audioFile?.write(from: buffer)
            } catch {
                print("‚ùå File write error at time \(time.sampleTime): \(error)")
            }
        }

        do {
            try engine.start()
            print("‚úÖ Audio engine started with buffer size 8192")
        } catch {
            print("‚ùå Engine start error:", error)
            stopListening()
            return
        }

        print("üéß Recording... Press STOP when done")
    }

    // –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–ª—É—à–∞–Ω–∏—è (–≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –∫–Ω–æ–ø–∫–æ–π)
    func stopListening() {
        guard isListening else { return }

        print("üõë Stopping recording...")
        isListening = false
        statusText = "‚è≥ –û–±—Ä–∞–±–æ—Ç–∫–∞..."

        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–≤–∏–∂–æ–∫ –∏ —É–¥–∞–ª—è–µ–º tap
        audioEngine?.stop()
        audioEngine?.inputNode.removeTap(onBus: 0)

        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–µ—Ä VAD
        silenceTimer?.invalidate()
        silenceTimer = nil

        // –í–∞–∂–Ω–æ: –∑–∞–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
        audioFile = nil
        audioEngine = nil

        print("‚úÖ Recording stopped")
        print("========== –ö–û–ù–ï–¶ –ó–ê–ü–ò–°–ò ==========\n")

        transcribeAudio()
    }

    // MARK: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–µ —Å VAD
    func startListeningAuto() {
        guard !isSpeaking && !isProcessing else {
            print("‚ö†Ô∏è Cannot start auto: isSpeaking=\(isSpeaking), isProcessing=\(isProcessing)")
            return
        }

        print("\n========== AUTO LISTENING (VAD) ==========")

        // ‚úÖ –û–ß–ò–©–ê–ï–ú –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ –Ω–æ–≤–æ–π –∑–∞–ø–∏—Å—å—é (–∫–∞–∫ –≤ —Ä—É—á–Ω–æ–º —Ä–µ–∂–∏–º–µ)
        recognizedText = ""
        responseText = ""
        lastCommandWasMusic = false  // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –ø—Ä–∏ –Ω–æ–≤–æ–º –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–∏

        statusText = "üëÇ –°–ª—É—à–∞—é..."
        lastSpeechTime = Date()  // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ç–∞–π–º–µ—Ä

        // –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –∑–∞–ø–∏—Å—å - –∏—Å–ø–æ–ª—å–∑—É–µ–º .playAndRecord —á—Ç–æ–±—ã –ù–ï —É–±–∏–≤–∞—Ç—å Spotify
        // .mixWithOthers –ø–æ–∑–≤–æ–ª—è–µ—Ç Spotify –∏–≥—Ä–∞—Ç—å –≤ —Ñ–æ–Ω–µ
        do {
            try AVAudioSession.sharedInstance().setCategory(.playAndRecord, mode: .default, options: [.allowBluetoothHFP, .duckOthers, .mixWithOthers, .defaultToSpeaker])
            try AVAudioSession.sharedInstance().setActive(true, options: .notifyOthersOnDeactivation)
            print("‚úÖ Audio session configured for VAD recording (Spotify compatible)")
        } catch {
            print("‚ùå Audio session VAD error:", error)
            return
        }

        let engine = AVAudioEngine()
        audioEngine = engine
        let input = engine.inputNode
        input.removeTap(onBus: 0)

        let inputFormat = input.outputFormat(forBus: 0)
        print("üé§ VAD format: \(inputFormat.sampleRate)Hz, \(inputFormat.channelCount) ch")

        // –°–æ–∑–¥–∞—ë–º —Ñ–∞–π–ª –¥–ª—è –∑–∞–ø–∏—Å–∏
        do {
            audioFile = try AVAudioFile(forWriting: audioFilename,
                                        settings: inputFormat.settings,
                                        commonFormat: .pcmFormatFloat32,
                                        interleaved: false)
            print("‚úÖ VAD audio file ready")
        } catch {
            print("‚ùå VAD file error:", error)
            return
        }

        // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º tap —Å –∞–Ω–∞–ª–∏–∑–æ–º –≥—Ä–æ–º–∫–æ—Å—Ç–∏
        input.installTap(onBus: 0, bufferSize: 8192, format: inputFormat) { [weak self] buffer, time in
            guard let self = self else { return }

            // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ —Ñ–∞–π–ª
            do {
                try self.audioFile?.write(from: buffer)
            } catch {
                print("‚ùå VAD write error at \(time.sampleTime): \(error)")
            }

            // –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≥—Ä–æ–º–∫–æ—Å—Ç—å (RMS - Root Mean Square)
            guard let channelData = buffer.floatChannelData?[0] else { return }
            let frames = buffer.frameLength
            var sum: Float = 0.0
            for i in 0..<Int(frames) {
                let sample = channelData[i]
                sum += sample * sample
            }
            let rms = sqrt(sum / Float(frames))
            let db = 20 * log10(rms)

            // –ï—Å–ª–∏ –≥—Ä–æ–º–∫–æ—Å—Ç—å –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ ‚Üí –æ–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ä–µ—á–∏
            if db > self.speechThreshold {
                DispatchQueue.main.async {
                    self.lastSpeechTime = Date()
                    if !self.isListening {
                        self.isListening = true
                        self.statusText = "üéôÔ∏è –ó–∞–ø–∏—Å—ã–≤–∞—é..."
                        print("üó£Ô∏è Speech detected! (level: \(String(format: "%.1f", db))dB)")
                    }
                }
            }
        }

        do {
            try engine.start()
            print("‚úÖ VAD engine started")
        } catch {
            print("‚ùå VAD engine error:", error)
            return
        }

        // –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–∞–π–º–µ—Ä –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–∏—à–∏–Ω—ã (–∫–∞–∂–¥—ã–µ 0.15 —Å–µ–∫)
        silenceTimer = Timer.scheduledTimer(withTimeInterval: 0.15, repeats: true) { [weak self] _ in
            guard let self = self else { return }

            let silenceDuration = Date().timeIntervalSince(self.lastSpeechTime)

            // –ï—Å–ª–∏ –±—ã–ª–æ –Ω–∞—á–∞—Ç–æ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–µ –ò –ø—Ä–æ—à–ª–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–∏—à–∏–Ω—ã ‚Üí –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º
            if self.isListening && silenceDuration > self.silenceThreshold {
                print("üîá Silence detected for \(String(format: "%.1f", silenceDuration))s ‚Üí stopping")
                self.stopListeningAuto()
            }
        }
    }

    // –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è
    func stopListeningAuto() {
        guard isListening else { return }

        print("üõë Auto-stopping recording...")
        isListening = false

        // –ú–ì–ù–û–í–ï–ù–ù–ê–Ø –†–ï–ê–ö–¶–ò–Ø - –≥–æ–≤–æ—Ä–∏–º —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–ø–∏—Å–∏!
        let quickReactions = ["–ê–≥–∞", "–ü–æ–Ω—è–ª", "–¢–∞–∫-—Ç–∞–∫", "–Ø—Å–Ω–æ", "–û–∫–µ–π", "–•–º", "–°–µ–∫—É–Ω–¥—É"]
        let reaction = quickReactions.randomElement() ?? "–ê–≥–∞"

        print("üí¨ Quick reaction (before transcription): \"\(reaction)\"")

        // –ì–æ–≤–æ—Ä–∏–º —Ä–µ–∞–∫—Ü–∏—é –°–†–ê–ó–£, –Ω–µ –∂–¥—ë–º
        say(reaction) {
            DispatchQueue.main.async {
                self.statusText = "üß† –†–∞—Å–ø–æ–∑–Ω–∞—é..."
            }
        }

        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–≤–∏–∂–æ–∫
        audioEngine?.stop()
        audioEngine?.inputNode.removeTap(onBus: 0)

        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–µ—Ä
        silenceTimer?.invalidate()
        silenceTimer = nil

        // –ó–∞–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª
        audioFile = nil
        audioEngine = nil

        print("‚úÖ Auto-recording stopped")
        print("========== END VAD ==========\n")

        transcribeAudio()
    }

    // –ü—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ (–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ–≥–æ)
    func interrupt() {
        print("üõë INTERRUPT - stopping everything")

        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å
        if isListening {
            audioEngine?.stop()
            audioEngine?.inputNode.removeTap(onBus: 0)
            audioFile = nil
            audioEngine = nil
            isListening = false
        }

        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–µ—Ä
        silenceTimer?.invalidate()
        silenceTimer = nil

        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ TTS
        player?.stop()
        isSpeaking = false

        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º—É–∑—ã–∫—É
        mediaPlayerManager?.stop()

        isProcessing = false
        statusText = "üõë –ü—Ä–µ—Ä–≤–∞–Ω–æ"

        // –ï—Å–ª–∏ –∞–≤—Ç–æ —Ä–µ–∂–∏–º ‚Üí –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ —Å–µ–∫—É–Ω–¥—É
        if isAutoMode {
            DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) {
                self.startListeningAuto()
            }
        }
    }

    // MARK: –û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
    func clearHistory() {
        conversationHistory.removeAll()
        recognizedText = ""
        responseText = ""
        statusText = "üóëÔ∏è –ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞"
        print("üóëÔ∏è Conversation history cleared")

        // –ß–µ—Ä–µ–∑ —Å–µ–∫—É–Ω–¥—É –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ –æ–±—ã—á–Ω—ã–π —Å—Ç–∞—Ç—É—Å
        DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) {
            if self.isAutoMode && !self.isListening && !self.isProcessing {
                self.statusText = "üëÇ –°–ª—É—à–∞—é..."
            } else if !self.isListening && !self.isProcessing {
                self.statusText = "üí§ –ñ–¥—É –∫–æ–º–∞–Ω–¥—ã"
            }
        }
    }

    // MARK: Whisper (—Å –¥–µ—Ç–∞–ª—å–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º)
    private func transcribeAudio() {
        isProcessing = true
        statusText = "üß† –†–∞—Å–ø–æ–∑–Ω–∞—é —Ä–µ—á—å..."
        print("\n========== WHISPER API ==========")

        guard let audioData = try? Data(contentsOf: audioFilename) else {
            print("‚ùå Cannot read audio file")
            DispatchQueue.main.async {
                self.statusText = "‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞"
                self.isProcessing = false
            }
            return
        }

        print("üì¶ Audio file size: \(audioData.count / 1024)KB")

        var req = URLRequest(url: URL(string: "https://api.openai.com/v1/audio/transcriptions")!)
        req.httpMethod = "POST"
        req.addValue("Bearer \(openAIKey)", forHTTPHeaderField: "Authorization")

        let boundary = "Boundary-\(UUID().uuidString)"
        req.setValue("multipart/form-data; boundary=\(boundary)", forHTTPHeaderField: "Content-Type")

        var body = Data()
        body.append("--\(boundary)\r\n".data(using: .utf8)!)
        body.append("Content-Disposition: form-data; name=\"file\"; filename=\"input.wav\"\r\n".data(using: .utf8)!)
        body.append("Content-Type: audio/wav\r\n\r\n".data(using: .utf8)!)
        body.append(audioData)

        // model
        body.append("\r\n--\(boundary)\r\n".data(using: .utf8)!)
        body.append("Content-Disposition: form-data; name=\"model\"\r\n\r\n".data(using: .utf8)!)
        body.append("whisper-1\r\n".data(using: .utf8)!)

        // —è–∑—ã–∫ ‚Äî —Ñ–∏–∫—Å–∏—Ä—É–µ–º —Ä—É—Å—Å–∫–∏–π
        body.append("--\(boundary)\r\n".data(using: .utf8)!)
        body.append("Content-Disposition: form-data; name=\"language\"\r\n\r\n".data(using: .utf8)!)
        body.append("ru\r\n".data(using: .utf8)!)

        // prompt ‚Äî –ø–æ–¥—Å–∫–∞–∑–∫–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (—É–º–µ–Ω—å—à–∞–µ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏)
        body.append("--\(boundary)\r\n".data(using: .utf8)!)
        body.append("Content-Disposition: form-data; name=\"prompt\"\r\n\r\n".data(using: .utf8)!)
        body.append("–†–∞–∑–≥–æ–≤–æ—Ä —Ä–µ–±–µ–Ω–∫–∞ —Å –≥–æ–ª–æ—Å–æ–≤—ã–º –ø–æ–º–æ—â–Ω–∏–∫–æ–º. –í–æ–ø—Ä–æ—Å—ã –ø—Ä–æ —É—á–µ–±—É, –∫–æ—Å–º–æ—Å, –∏–≥—Ä—ã.\r\n".data(using: .utf8)!)

        // temperature ‚Äî —Ç–æ—á–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (0 = –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ)
        body.append("--\(boundary)\r\n".data(using: .utf8)!)
        body.append("Content-Disposition: form-data; name=\"temperature\"\r\n\r\n".data(using: .utf8)!)
        body.append("0.0\r\n".data(using: .utf8)!)

        body.append("--\(boundary)--\r\n".data(using: .utf8)!)
        req.httpBody = body

        print("üì§ Sending to Whisper API...")
        let startTime = Date()

        URLSession.shared.dataTask(with: req) { data, response, error in
            let elapsed = Date().timeIntervalSince(startTime)
            print("‚è±Ô∏è Whisper response time: \(String(format: "%.1f", elapsed))s")

            if let error = error {
                print("‚ùå Whisper error: \(error.localizedDescription)")
                DispatchQueue.main.async {
                    self.statusText = "‚ùå –û—à–∏–±–∫–∞ —Å–µ—Ç–∏"
                    self.isProcessing = false
                }
                return
            }

            guard let data = data else {
                print("‚ùå No data received")
                DispatchQueue.main.async {
                    self.statusText = "‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
                    self.isProcessing = false
                }
                return
            }

            guard let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any] else {
                print("‚ùå Cannot parse JSON")
                if let responseString = String(data: data, encoding: .utf8) {
                    print("Raw response: \(responseString)")
                }
                DispatchQueue.main.async {
                    self.statusText = "‚ùå –û—à–∏–±–∫–∞ API"
                    self.isProcessing = false
                }
                return
            }

            guard let text = json["text"] as? String else {
                print("‚ùå No 'text' field in response")
                print("JSON: \(json)")
                DispatchQueue.main.async {
                    self.statusText = "‚ùå –ù–µ—Ç —Ç–µ–∫—Å—Ç–∞"
                    self.isProcessing = false
                }
                return
            }

            let trimmedText = text.trimmingCharacters(in: .whitespacesAndNewlines)
            print("‚úÖ Recognized: \"\(trimmedText)\"")

            // ‚úÖ –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ú–£–°–û–†–ù–´–• –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–ô (Whisper –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏)
            let junkPhrases = [
                "—Ç–µ–º–∞ –∂–∏–≤–æ—Ç–Ω—ã–µ –∏ —Ñ—Ä—É–∫—Ç—ã",
                "–≤–æ–ø—Ä–æ—Å—ã –ø—Ä–æ —É—á–µ–±—É",
                "–∫–∏–Ω–æ –∏ —Å–ø–æ—Ä—Ç",
                "—Å–ø–∞—Å–∏–±–æ –∑–∞ –ø—Ä–æ—Å–º–æ—Ç—Ä",
                "–ø–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å –Ω–∞ –∫–∞–Ω–∞–ª",
                "—Å—Ç–∞–≤—å—Ç–µ –ª–∞–π–∫–∏",
                "—Å—É–±—Ç–∏—Ç—Ä—ã",
                "–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å–ª–µ–¥—É–µ—Ç",
                "–º—É–∑—ã–∫–∞",
                "–∞–ø–ª–æ–¥–∏—Å–º–µ–Ω—Ç—ã"
            ]

            let lowercased = trimmedText.lowercased()
            let isJunk = junkPhrases.contains { lowercased.contains($0) }

            if isJunk {
                print("‚ö†Ô∏è JUNK detected - ignoring Whisper hallucination: \"\(trimmedText)\"")
                DispatchQueue.main.async {
                    self.statusText = "ü§∑ –ù–µ —Ä–∞—Å—Å–ª—ã—à–∞–ª"
                    self.isProcessing = false

                    // –í –∞–≤—Ç–æ —Ä–µ–∂–∏–º–µ ‚Üí —Å—Ä–∞–∑—É –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å–ª—É—à–∞—Ç—å
                    if self.isAutoMode {
                        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                            self.startListeningAuto()
                        }
                    }
                }
                print("========== END WHISPER ==========\n")
                return
            }

            if trimmedText.isEmpty || trimmedText.count < 2 {
                print("‚ö†Ô∏è Too short or empty - nothing heard")
                DispatchQueue.main.async {
                    self.statusText = "ü§∑ –ù–∏—á–µ–≥–æ –Ω–µ —É—Å–ª—ã—à–∞–ª"
                    self.recognizedText = "(–ø—É—Å—Ç–æ)"
                    self.isProcessing = false

                    // –í –∞–≤—Ç–æ —Ä–µ–∂–∏–º–µ ‚Üí –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å–ª—É—à–∞—Ç—å
                    if self.isAutoMode {
                        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                            self.startListeningAuto()
                        }
                    }
                }
                print("========== END WHISPER ==========\n")
                return
            }

            print("========== END WHISPER ==========\n")

            DispatchQueue.main.async {
                self.recognizedText = trimmedText
                self.askGPT(trimmedText)
            }
        }.resume()
    }

    // MARK: GPT (—Å –∏—Å—Ç–æ—Ä–∏–µ–π —Ä–∞–∑–≥–æ–≤–æ—Ä–∞)
    private func askGPT(_ text: String) {
        // Allow empty text only for function call follow-ups (when conversation history has function results)
        if text.isEmpty && conversationHistory.isEmpty {
            print("‚ö†Ô∏è Empty text for GPT")
            DispatchQueue.main.async {
                self.isProcessing = false
                self.statusText = "üí§ –ñ–¥—É –∫–æ–º–∞–Ω–¥—ã"
            }
            return
        }

        // –†–µ–∞–∫—Ü–∏—è —É–∂–µ –±—ã–ª–∞ —Å–∫–∞–∑–∞–Ω–∞ –≤ stopListeningAuto()
        // –°—Ä–∞–∑—É –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å "–¥—É–º–∞—é"
        DispatchQueue.main.async {
            self.statusText = "ü§î –î—É–º–∞—é..."
        }

        print("\n========== GPT API ==========")
        print("üìù User input: \"\(text)\"")

        let url = URL(string: "https://api.openai.com/v1/chat/completions")!

        // ‚úÖ –°–û–ö–†–ê–©–ï–ù–ù–´–ô –ü–†–û–ú–ü–¢ (—ç–∫–æ–Ω–æ–º–∏—è —Ç–æ–∫–µ–Ω–æ–≤, –±—ã—Å—Ç—Ä–µ–µ –æ–±—Ä–∞–±–æ—Ç–∫–∞)
        var systemPrompt = """
        –¢—ã –ú–∞–ª–æ–π ‚Äî –≥–æ–ª–æ—Å–æ–≤–æ–π –ø–æ–º–æ—â–Ω–∏–∫. –ì–æ–≤–æ—Ä–∏—à—å —Å –§—ë–¥–æ—Ä–æ–º (15 –ª–µ—Ç, –Ω–µ–∑—Ä—è—á–∏–π, 8 –∫–ª–∞—Å—Å).
        –°—Ç–∏–ª—å: –Ω–∞ —Ä–∞–≤–Ω—ã—Ö, –±–µ–∑ —Å—é—Å—é–∫–∞–Ω—å—è, —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å–ª–µ–Ω–≥ OK, –º–æ–∂–Ω–æ —à—É—Ç–∏—Ç—å.
        –û–ø–∏—Å—ã–≤–∞—è –ø—Ä–µ–¥–º–µ—Ç—ã ‚Üí —É–ø–æ–º–∏–Ω–∞–π —Ñ–æ—Ä–º—É, —Ä–∞–∑–º–µ—Ä, —Ç–µ–∫—Å—Ç—É—Ä—É (–æ–Ω –Ω–µ–∑—Ä—è—á–∏–π).
        –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ (2-4 —Ñ—Ä–∞–∑—ã). –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞ –º–æ–∂–Ω–æ.
        """

        if mediaPlayerManager?.isAuthorized == true {
            systemPrompt += """

            –í–ê–ñ–ù–û: –£ —Ç–µ–±—è –µ—Å—Ç—å Apple Music —Ñ—É–Ω–∫—Ü–∏–∏. –ö–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –≤–∫–ª—é—á–∏—Ç—å –º—É–∑—ã–∫—É - –°–†–ê–ó–£ –≤—ã–∑—ã–≤–∞–π —Ñ—É–Ω–∫—Ü–∏—é, –ù–ï —Å–ø—Ä–∞—à–∏–≤–∞–π –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è.
            –ü—Ä–∏–º–µ—Ä—ã:
            - "–í–∫–ª—é—á–∏ –ú–æ—Ä–≥–µ–Ω—à—Ç–µ—Ä–Ω–∞" ‚Üí –≤—ã–∑–æ–≤–∏ music_search_and_play("–ú–æ—Ä–≥–µ–Ω—à—Ç–µ—Ä–Ω")
            - "–í–∫–ª—é—á–∏ The Head and the Heart" ‚Üí –≤—ã–∑–æ–≤–∏ music_search_and_play("The Head and the Heart")
            - "–ü–æ—Å—Ç–∞–≤—å –Ω–∞ –ø–∞—É–∑—É" / "–°—Ç–æ–ø" / "–û—Å—Ç–∞–Ω–æ–≤–∏" ‚Üí –≤—ã–∑–æ–≤–∏ music_pause
            - "–°–ª–µ–¥—É—é—â–∏–π —Ç—Ä–µ–∫" / "–î–∞–ª—å—à–µ" / "–ù–µ–∫—Å—Ç" ‚Üí –≤—ã–∑–æ–≤–∏ music_next
            - "–ü—Ä–æ–¥–æ–ª–∂–∏" / "–ò–≥—Ä–∞–π" ‚Üí –≤—ã–∑–æ–≤–∏ music_play

            –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ù–ï –ü–ï–†–ï–í–û–î–ò –Ω–∞–∑–≤–∞–Ω–∏—è –∞—Ä—Ç–∏—Å—Ç–æ–≤ –∏ –ø–µ—Å–µ–Ω! –ü–µ—Ä–µ–¥–∞–≤–∞–π –∏—Ö –í –¢–û–ß–ù–û–°–¢–ò –∫–∞–∫ —É—Å–ª—ã—à–∞–ª!
            - "–í–∫–ª—é—á–∏ The Head and the Heart" ‚Üí music_search_and_play("The Head and the Heart") ‚úÖ
            - "–í–∫–ª—é—á–∏ The Head and the Heart" ‚Üí music_search_and_play("–ì–æ–ª–æ–≤–∞ –∏ –°–µ—Ä–¥—Ü–µ") ‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û!
            - "–í–∫–ª—é—á–∏ Coldplay" ‚Üí music_search_and_play("Coldplay") ‚úÖ
            - "–í–∫–ª—é—á–∏ Imagine Dragons" ‚Üí music_search_and_play("Imagine Dragons") ‚úÖ

            –û–ß–ï–ù–¨ –í–ê–ñ–ù–û: –°–ª–æ–≤–∞ "—Å—Ç–æ–ø", "–æ—Å—Ç–∞–Ω–æ–≤–∏", "—Ö–≤–∞—Ç–∏—Ç", "–≤—ã–∫–ª—é—á–∏ –º—É–∑—ã–∫—É" ‚Üí –í–°–ï–ì–î–ê –≤—ã–∑—ã–≤–∞–π music_pause!

            –ö–æ–≥–¥–∞ –≤–∫–ª—é—á–∞–µ—à—å –º—É–∑—ã–∫—É - –æ—Ç–≤–µ—á–∞–π –Ω–∞–∑–≤–∞–Ω–∏–µ–º –∞—Ä—Ç–∏—Å—Ç–∞ –∏ —Ç—Ä–µ–∫–∞ –ë–ï–ó –ü–ï–†–ï–í–û–î–ê.
            –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤:
            - –ï—Å–ª–∏ –≤–∫–ª—é—á–∏–ª –ú–æ—Ä–≥–µ–Ω—à—Ç–µ—Ä–Ω–∞ "Cadillac" ‚Üí —Å–∫–∞–∂–∏ "–ú–æ—Ä–≥–µ–Ω—à—Ç–µ—Ä–Ω, –ö–∞–¥–∏–ª–ª–∞–∫"
            - –ï—Å–ª–∏ –≤–∫–ª—é—á–∏–ª Coldplay "Yellow" ‚Üí —Å–∫–∞–∂–∏ "Coldplay, Yellow" (–ù–ï "–ö–æ–ª–¥–ø–ª–µ–π, –ô–µ–ª–ª–æ—É"!)
            - –ï—Å–ª–∏ –≤–∫–ª—é—á–∏–ª The Head and the Heart ‚Üí —Å–∫–∞–∂–∏ "The Head and the Heart, [–Ω–∞–∑–≤–∞–Ω–∏–µ —Ç—Ä–µ–∫–∞]"
            - –ù–ò–ö–û–ì–î–ê –Ω–µ –≥–æ–≤–æ—Ä–∏ "–í–∫–ª—é—á–∞—é", "–õ–æ–≤–∏", "–ò–≥—Ä–∞–µ—Ç" - –¢–û–õ–¨–ö–û –Ω–∞–∑–≤–∞–Ω–∏–µ!
            """
        }

        // ‚úÖ –î–û–ë–ê–í–õ–Ø–ï–ú –¢–ï–ö–£–©–ò–ô –í–û–ü–†–û–° –í –ò–°–¢–û–†–ò–Æ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –ø—É—Å—Ç–æ–π)
        if !text.isEmpty {
            conversationHistory.append(["role": "user", "content": text])
        }

        // ‚úÖ –°–ö–û–õ–¨–ó–Ø–©–ï–ï –û–ö–ù–û: —É–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –ø–∞—Ä—ã, –µ—Å–ª–∏ –∏—Å—Ç–æ—Ä–∏—è —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è
        // –ö–∞–∂–¥–∞—è –ø–∞—Ä–∞ = user + assistant = 2 —Å–æ–æ–±—â–µ–Ω–∏—è
        // –•—Ä–∞–Ω–∏–º maxHistoryPairs * 2 = 8 —Å–æ–æ–±—â–µ–Ω–∏–π (4 –ø–∞—Ä—ã)
        while conversationHistory.count > maxHistoryPairs * 2 {
            conversationHistory.removeFirst(2)  // –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä–µ–π—à—É—é –ø–∞—Ä—É (user + assistant)
            print("üóëÔ∏è Removed oldest conversation pair (sliding window)")
        }

        // ‚úÖ –§–û–†–ú–ò–†–£–ï–ú MESSAGES: —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç + –≤—Å—è –∏—Å—Ç–æ—Ä–∏—è
        var messages: [[String: Any]] = [
            ["role": "system", "content": systemPrompt]
        ]
        messages.append(contentsOf: conversationHistory)

        print("üìö Conversation history: \(conversationHistory.count) messages (\(conversationHistory.count / 2) pairs)")

        // Music tools (only if authorized) - using new tools format for gpt-4o-mini
        var tools: [[String: Any]] = []
        if mediaPlayerManager?.isAuthorized == true {
            tools = [
                [
                    "type": "function",
                    "function": [
                        "name": "music_search_and_play",
                        "description": "–ù–ï–ú–ï–î–õ–ï–ù–ù–û –≤–∫–ª—é—á–∏—Ç—å –º—É–∑—ã–∫—É –∏–∑ Apple Music. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≥–æ–≤–æ—Ä–∏—Ç '–≤–∫–ª—é—á–∏', '–ø–æ—Å—Ç–∞–≤—å', '–∏–≥—Ä–∞–π' + –Ω–∞–∑–≤–∞–Ω–∏–µ –∞—Ä—Ç–∏—Å—Ç–∞/–ø–µ—Å–Ω–∏. –ù–ï —Å–ø—Ä–∞—à–∏–≤–∞–π –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è - —Å—Ä–∞–∑—É –≤—ã–∑—ã–≤–∞–π —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é.",
                        "parameters": [
                            "type": "object",
                            "properties": [
                                "query": [
                                    "type": "string",
                                    "description": "–ù–∞–∑–≤–∞–Ω–∏–µ –∞—Ä—Ç–∏—Å—Ç–∞ –∏–ª–∏ –ø–µ—Å–Ω–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä: '–ú–æ—Ä–≥–µ–Ω—à—Ç–µ—Ä–Ω', 'Imagine Dragons', 'Shape of You')"
                                ]
                            ],
                            "required": ["query"]
                        ]
                    ]
                ],
                [
                    "type": "function",
                    "function": [
                        "name": "music_play",
                        "description": "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –º—É–∑—ã–∫–∏",
                        "parameters": ["type": "object", "properties": [:]]
                    ]
                ],
                [
                    "type": "function",
                    "function": [
                        "name": "music_pause",
                        "description": "–ü–æ—Å—Ç–∞–≤–∏—Ç—å –º—É–∑—ã–∫—É –Ω–∞ –ø–∞—É–∑—É –∏–ª–∏ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å",
                        "parameters": ["type": "object", "properties": [:]]
                    ]
                ],
                [
                    "type": "function",
                    "function": [
                        "name": "music_next",
                        "description": "–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π —Ç—Ä–µ–∫",
                        "parameters": ["type": "object", "properties": [:]]
                    ]
                ],
                [
                    "type": "function",
                    "function": [
                        "name": "music_previous",
                        "description": "–í–µ—Ä–Ω—É—Ç—å—Å—è –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É —Ç—Ä–µ–∫—É",
                        "parameters": ["type": "object", "properties": [:]]
                    ]
                ]
            ]
        }

        var body: [String: Any] = [
            "model": "gpt-4o-mini",  // –ò–∑–º–µ–Ω–µ–Ω–æ —Å gpt-3.5-turbo - –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å function calling
            "messages": messages,
            "max_tokens": 150
        ]

        if !tools.isEmpty {
            body["tools"] = tools
            body["tool_choice"] = "auto"
        }

        var req = URLRequest(url: url)
        req.httpMethod = "POST"
        req.addValue("Bearer \(openAIKey)", forHTTPHeaderField: "Authorization")
        req.addValue("application/json", forHTTPHeaderField: "Content-Type")
        req.httpBody = try? JSONSerialization.data(withJSONObject: body)

        print("üì§ Sending to GPT...")
        print("üîç DEBUG - Request body keys: \(body.keys.sorted())")
        print("üîç DEBUG - Model: \(body["model"] as? String ?? "unknown")")
        print("üîç DEBUG - Has tools: \(!tools.isEmpty)")
        print("üîç DEBUG - Messages count: \((body["messages"] as? [Any])?.count ?? 0)")
        let startTime = Date()

        URLSession.shared.dataTask(with: req) { data, response, error in
            let elapsed = Date().timeIntervalSince(startTime)
            print("‚è±Ô∏è GPT response time: \(String(format: "%.1f", elapsed))s")

            if let error = error {
                print("‚ùå GPT error: \(error.localizedDescription)")
                DispatchQueue.main.async {
                    self.statusText = "‚ùå –û—à–∏–±–∫–∞ GPT"
                    self.isProcessing = false
                }
                return
            }

            guard let data = data,
                  let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any] else {
                print("‚ùå Cannot parse GPT response")
                DispatchQueue.main.async {
                    self.statusText = "‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞"
                    self.isProcessing = false
                }
                return
            }

            guard let choices = json["choices"] as? [[String: Any]],
                  let msg = choices.first?["message"] as? [String: Any] else {
                print("‚ùå No message in GPT response")
                print("JSON: \(json)")
                DispatchQueue.main.async {
                    self.statusText = "‚ùå –ù–µ—Ç –æ—Ç–≤–µ—Ç–∞"
                    self.isProcessing = false
                }
                return
            }

            // DEBUG: Print full GPT response to see what's happening
            print("üîç DEBUG - Full GPT message: \(msg)")
            print("üîç DEBUG - Has tool_calls: \(msg["tool_calls"] != nil)")
            print("üîç DEBUG - Content: \(msg["content"] as? String ?? "nil")")
            if !tools.isEmpty {
                print("üîç DEBUG - Tools were sent: \(tools.count) tools")
            } else {
                print("üîç DEBUG - No tools were sent in request")
            }

            // Check if GPT wants to call a tool (new format)
            if let toolCalls = msg["tool_calls"] as? [[String: Any]],
               let firstToolCall = toolCalls.first,
               let function = firstToolCall["function"] as? [String: Any],
               let functionName = function["name"] as? String,
               let argumentsString = function["arguments"] as? String {

                let toolCallId = firstToolCall["id"] as? String ?? "unknown"
                print("üéµ GPT wants to call tool: \(functionName)")
                print("üìù Tool call ID: \(toolCallId)")
                print("üìù Arguments: \(argumentsString)")

                // Execute Music function
                self.executeMusicFunction(name: functionName, arguments: argumentsString) { result in
                    // After function execution, ask GPT again with tool result (new format)
                    self.conversationHistory.append([
                        "role": "assistant",
                        "tool_calls": toolCalls
                    ] as [String : Any])
                    self.conversationHistory.append([
                        "role": "tool",
                        "tool_call_id": toolCallId,
                        "name": functionName,
                        "content": result
                    ])

                    // Recursive call to get final response
                    self.askGPT("")
                }
                return
            }

            // Normal text response
            guard let reply = msg["content"] as? String else {
                print("‚ùå No content in GPT response")
                print("JSON: \(json)")
                DispatchQueue.main.async {
                    self.statusText = "‚ùå –ù–µ—Ç –æ—Ç–≤–µ—Ç–∞"
                    self.isProcessing = false
                }
                return
            }

            print("‚úÖ GPT reply: \"\(reply)\"")

            // ‚úÖ –î–û–ë–ê–í–õ–Ø–ï–ú –û–¢–í–ï–¢ GPT –í –ò–°–¢–û–†–ò–Æ
            self.conversationHistory.append(["role": "assistant", "content": reply])
            print("üìö Added assistant response to history (now \(self.conversationHistory.count) messages)")
            print("========== END GPT ==========\n")

            // –ú–û–ú–ï–ù–¢–ê–õ–¨–ù–û –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            DispatchQueue.main.async {
                self.responseText = reply
                self.statusText = "üó£Ô∏è –ì–æ—Ç–æ–≤–ª—é –æ–∑–≤—É—á–∫—É..."
            }

            // TTS –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ (–Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç UI)
            self.say(reply) {
                DispatchQueue.main.async {
                    self.isProcessing = false
                    // –ï—Å–ª–∏ –∞–≤—Ç–æ —Ä–µ–∂–∏–º ‚Üí –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å–ª—É—à–∞—Ç—å
                    // –ù–û: –µ—Å–ª–∏ —Ç–æ–ª—å–∫–æ —á—Ç–æ –≤–∫–ª—é—á–∏–ª–∏ –º—É–∑—ã–∫—É - –ù–ï –∑–∞–ø—É—Å–∫–∞–µ–º –∞–≤—Ç–æ-–ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–µ
                    if self.isAutoMode && !self.lastCommandWasMusic {
                        self.startListeningAuto()
                    } else {
                        self.statusText = "üí§ –ñ–¥—É –∫–æ–º–∞–Ω–¥—ã"
                        // –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –º—É–∑—ã–∫–∏ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π –∫–æ–º–∞–Ω–¥—ã
                        self.lastCommandWasMusic = false
                    }
                }
            }
        }.resume()
    }

    // MARK: - Music Function Execution
    private func executeMusicFunction(name: String, arguments: String, completion: @escaping (String) -> Void) {
        guard let music = mediaPlayerManager else {
            completion("{\"error\": \"MusicKit not initialized\"}")
            return
        }

        // Parse arguments JSON
        guard let argsData = arguments.data(using: .utf8),
              let args = try? JSONSerialization.jsonObject(with: argsData) as? [String: Any] else {
            completion("{\"error\": \"Invalid arguments\"}")
            return
        }

        print("üéµ Executing Music function: \(name)")

        // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ –¥–ª—è –∫–æ–º–∞–Ω–¥ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è (–∫—Ä–æ–º–µ –ø–∞—É–∑—ã)
        if name == "music_search_and_play" || name == "music_play" || name == "music_next" || name == "music_previous" {
            self.lastCommandWasMusic = true
        }

        switch name {
        case "music_search_and_play":
            guard let query = args["query"] as? String else {
                completion("{\"error\": \"Missing query parameter\"}")
                return
            }

            music.searchAndPlay(query: query) { success, message in
                if success {
                    completion("{\"success\": true, \"message\": \"\(message)\"}")
                } else {
                    completion("{\"success\": false, \"message\": \"\(message)\"}")
                }
            }

        case "music_play":
            music.play { success, message in
                completion("{\"success\": \(success), \"message\": \"\(message)\"}")
            }

        case "music_pause":
            music.pause { success, message in
                completion("{\"success\": \(success), \"message\": \"\(message)\"}")
            }

        case "music_next":
            music.next { success, message in
                completion("{\"success\": \(success), \"message\": \"\(message)\"}")
            }

        case "music_previous":
            music.previous { success, message in
                completion("{\"success\": \(success), \"message\": \"\(message)\"}")
            }

        default:
            completion("{\"error\": \"Unknown function: \(name)\"}")
        }
    }

    // MARK: TTS (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏)
    func say(_ text: String, completion: (() -> Void)? = nil) {
        print("\n========== TTS API ==========")
        print("üí¨ Text to speak: \"\(text)\"")

        // –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Ç–æ–ª—å–∫–æ –≤ main thread
        DispatchQueue.main.async {
            self.statusText = "üó£Ô∏è –ì–æ–≤–æ—Ä—é..."
        }

        guard let url = URL(string: "https://api.openai.com/v1/audio/speech") else {
            print("‚ùå Invalid TTS URL")
            completion?()
            return
        }

        let json: [String: Any] = [
            "model": "gpt-4o-mini-tts",
            "voice": "alloy",
            "input": text,
            "speed": 1.15  // –£–≤–µ–ª–∏—á–∏–ª–∏ —Å–∫–æ—Ä–æ—Å—Ç—å —Å 1.0 –¥–æ 1.15 –¥–ª—è –±—ã—Å—Ç—Ä–æ–π —Ä–µ—á–∏
        ]

        var req = URLRequest(url: url)
        req.httpMethod = "POST"
        req.addValue("Bearer \(openAIKey)", forHTTPHeaderField: "Authorization")
        req.addValue("application/json", forHTTPHeaderField: "Content-Type")
        req.httpBody = try? JSONSerialization.data(withJSONObject: json)

        print("üì§ Requesting TTS...")
        let startTime = Date()

        URLSession.shared.dataTask(with: req) { data, response, error in
            let elapsed = Date().timeIntervalSince(startTime)
            print("‚è±Ô∏è TTS response time: \(String(format: "%.1f", elapsed))s")

            if let error = error {
                print("‚ùå TTS error:", error.localizedDescription)
                DispatchQueue.main.async {
                    self.statusText = "‚ùå –û—à–∏–±–∫–∞ TTS"
                }
                completion?()
                return
            }

            guard let data = data, !data.isEmpty else {
                print("‚ùå Empty TTS response")
                DispatchQueue.main.async {
                    self.statusText = "‚ùå –ù–µ—Ç –∞—É–¥–∏–æ"
                }
                completion?()
                return
            }

            print("‚úÖ TTS received (\(data.count / 1024)KB)")

            let tmp = FileManager.default.temporaryDirectory.appendingPathComponent("speech.mp3")
            do {
                try data.write(to: tmp, options: .atomic)
                print("‚úÖ TTS file saved: \(tmp.path)")
                DispatchQueue.main.async {
                    self.playAudio(from: tmp, completion: completion)
                }
            } catch {
                print("‚ùå TTS write error:", error)
                completion?()
            }
        }.resume()
    }

    private func playAudio(from url: URL, completion: (() -> Void)? = nil) {
        print("üîä Starting playback...")

        do {
            // –ò—Å–ø–æ–ª—å–∑—É–µ–º .playAndRecord —Å .duckOthers —á—Ç–æ–±—ã –ù–ï –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å Spotify
            // .duckOthers –ø–æ–Ω–∏–∂–∞–µ—Ç –≥—Ä–æ–º–∫–æ—Å—Ç—å –¥—Ä—É–≥–æ–≥–æ –∞—É–¥–∏–æ (Spotify) –≤–º–µ—Å—Ç–æ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
            // .mixWithOthers –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–≥—Ä–∞—Ç—å –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ —Å –¥—Ä—É–≥–∏–º–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è–º–∏
            try AVAudioSession.sharedInstance().setCategory(.playAndRecord, mode: .default, options: [.duckOthers, .defaultToSpeaker, .mixWithOthers])
            try AVAudioSession.sharedInstance().setActive(true, options: .notifyOthersOnDeactivation)
            print("‚úÖ Audio session configured for TTS (ducking Spotify)")

            isSpeaking = true
            let p = try AVAudioPlayer(contentsOf: url)
            player = p

            p.prepareToPlay()
            let success = p.play()

            if !success {
                print("‚ùå Failed to start audio playback")
                self.isSpeaking = false
                DispatchQueue.main.async {
                    self.statusText = "‚ùå –û—à–∏–±–∫–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è"
                }
                completion?()
                return
            }

            print("üîä Playing audio (duration: \(String(format: "%.1f", p.duration))s)")

            // –ñ–¥–µ–º –æ–∫–æ–Ω—á–∞–Ω–∏—è + –Ω–µ–±–æ–ª—å—à–æ–π –±—É—Ñ–µ—Ä
            DispatchQueue.main.asyncAfter(deadline: .now() + p.duration + 0.3) {
                print("‚úÖ Playback finished")
                print("========== END TTS ==========\n")
                self.isSpeaking = false

                // –ü–æ—Å–ª–µ TTS –¥–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ–º –∞—É–¥–∏–æ-—Å–µ—Å—Å–∏—é —Å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ–º –¥—Ä—É–≥–∏—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π
                // –≠—Ç–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç –≥—Ä–æ–º–∫–æ—Å—Ç—å Spotify
                do {
                    try AVAudioSession.sharedInstance().setActive(false, options: .notifyOthersOnDeactivation)
                    print("üîä Audio session deactivated, Spotify should resume normal volume")
                } catch {
                    print("‚ö†Ô∏è Could not deactivate audio session: \(error)")
                }

                completion?()
            }
        } catch {
            print("‚ùå TTS play error:", error)
            self.isSpeaking = false
            DispatchQueue.main.async {
                self.statusText = "‚ùå –û—à–∏–±–∫–∞ –ø–ª–µ–µ—Ä–∞"
            }
            completion?()
        }
    }
}
